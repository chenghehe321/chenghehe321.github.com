<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title><![CDATA[Carl Cheng's Home]]></title>
  <subtitle><![CDATA[A day is a miniature of eternity.   --  R. W. Emerson]]></subtitle>
  <link href="/atom.xml" rel="self"/>
  <link href="http://chenghehe321.github.io/"/>
  <updated>2014-12-02T17:58:14.401Z</updated>
  <id>http://chenghehe321.github.io/</id>
  
  <author>
    <name><![CDATA[Carl Cheng]]></name>
    <email><![CDATA[chengy1013@gmail.com]]></email>
  </author>
  
  <generator uri="http://zespia.tw/hexo/">Hexo</generator>
  
  <entry>
    <title><![CDATA[参数算法(Parameterized Algorithm)拾遗]]></title>
    <link href="http://chenghehe321.github.io/2014/12/03/parameterizedAlgorithm/"/>
    <id>http://chenghehe321.github.io/2014/12/03/parameterizedAlgorithm/</id>
    <published>2014-12-02T17:55:39.000Z</published>
    <updated>2014-12-02T17:57:51.000Z</updated>
    <content type="html"><![CDATA[<h3 id="NP问题">NP问题</h3>
<p>距离上次参与参数算法的报告已经很久了，再不回顾和记录，怕是早就忘得一干二净了。<br>说起参数算法，要从NP问题开始回顾。NP(Nondeterministic polynomial-time)问题是指一类问题可以在多项式时间内验证一个解是不是该问题的解，但是要在多项式时间内找到该问题的所有解却是很难甚至是不可能的。在实际解决问题时如果找到一个NP难问题在多项式时间内规约(Reduction)到这个问题上，则能证明该问题也是NP难的，想要解决是不容易的。<a id="more"></a>在现有的NP难问题中存在如下图所示的规约链条</p>
<p><center><br><img src="http://carl-cheng.qiniudn.com/%E8%A7%84%E7%BA%A6%E9%93%BE%E6%9D%A1%28%E9%AB%98%E6%B8%85%29.png?attname=&e=1417597773&token=ERmvz_0iOqb5Ng5qyfJ7Rcc-cZKOi2fzkZd0y8oB:D5d6dzV-81xz02L1nKtscwc8Lfk" alt="规约链条" height="330" width="700"><br></center><br>在规约链条中，如果其中某一个问题能找到多项式时间的算法，其他所有问题都能使用该算法来达到多项式时间，就能证明$P=NP$了。这里可以脑洞大开$P=NP$了世界会发生怎样的事情。。。。。。好像最起码近似算法随机算法启发式算法这些牺牲精确结果去换时间的算法统统白发展了。<br>现阶段尽管可能只是存在指数时间的算法，但问题依然是需要被解决的。为了能尽量大的提高问题的输入规模，普遍有两种解决思路。一是如果允许可以退而求其次，使用近似算法，随机算法，启发式算法等非精确算法，这样虽然得到的结果不是准确的，但是能在多项式时间内完成。但是如果问题需要的就是问题精确的解。比如在生物计算的一些问题上，结果需要精确到某一个DNA上，得到结果可能是某几个DNA是没有大的意义的，在这样的情况下，就有第二种解决思路-参数算法。</p>
<h3 id="参数算法">参数算法</h3>
<p>NP难的问题时间复杂度都是指数级别，将问题解空间遍历一次的时间复杂度是$O(2^n)$，但是最后解集的大小k和总输入大小n相差可能会很大，于是就想到如果能将时间复杂度从$O(2^n)$降低到$O(n^C*2^k)$，这样我们能处理的数据规模会变大不少。例如在点覆盖问题(Vertex Cover)，边支配集问题(Edge Dominating Set)中，尽管问题输入规模为n，但是最后找到的解集k可能并不大。以边支配集为例，该问题是找到一个边的集合，当在图中删掉找到的这些边和边的端点之后，图中不再存在边。还有一种理解是找到一个边的集合，图中另外的边和集合中的所有边都不相邻。问题也有可以相互规约的等价的两种问法：</p>
<ol>
<li>Search Problem: 找到最小的边支配集；</li>
<li>Decision Problem：问是否存在大小不超过k的边支配集。</li>
</ol>
<p>这个问题最开始在1979年被MR Garey和DS Johnson证明是NP完全问题，然后在1980年被Yannakakis和Gavril证明在最大度为3的二分图中依然是NP完全问题。肖鸣宇老师在2012年发表文章给出了一般图和3度图中时间复杂度分别为$O(2.4181^k)$和$O(2.1479^k)$的算法，改进了Fernau在2006年给出的在一般图中$O(2.6181^k)$算法。现在最新的成果还是肖老师在2013年给出在一般图中的算法，时间复杂度降低到$O(2.3147^k)$。<br>在具体的算法技巧上参数算法有五类技术：(1)分支(Branching)技术；(2)核心化(Kernelization)技术；(3)归纳技术；(4)双赢(Win/Win)技术；(5)其他。这个问题加上点覆盖问题(Vertex Cover)都是采用分支技术去解决。</p>
<h3 id="固定参数可解(Fixed_Parameter_Tractable)">固定参数可解(Fixed Parameter Tractable)</h3>
<p>和P与NP的分类相似，能找到参数算法的问题被称为FPT(Fixed Parameter Tractable)问题，这类问题之间的规约则不用在多项式时间内完成，是可以用指数时间完成的，称为FPT-Time。而暂时没找到的则用W分层(W-Hierarchy)进一步分类为W[t]-Hard，其中t为该问题通过FPT规约到WCNF-2SAT问题的传递次数。大多数固定参数不可解(Fixed Parameter Intractable)问题都属于W[1]-Hard或W[2]-Hard，例如经典的最大团问题(Maximum Clique)，独立集问题(Independent Set)等都属于W[1]-Hard。</p>
<p>参数算法大体上如此，只是细节上远远不够，有空再继续研究。</p>
]]></content>
    <summary type="html">
    <![CDATA[<h3 id="NP问题">NP问题</h3>
<p>距离上次参与参数算法的报告已经很久了，再不回顾和记录，怕是早就忘得一干二净了。<br>说起参数算法，要从NP问题开始回顾。NP(Nondeterministic polynomial-time)问题是指一类问题可以在多项式时间内验证一个解是不是该问题的解，但是要在多项式时间内找到该问题的所有解却是很难甚至是不可能的。在实际解决问题时如果找到一个NP难问题在多项式时间内规约(Reduction)到这个问题上，则能证明该问题也是NP难的，想要解决是不容易的。]]>
    
    </summary>
    
      <category term="Algorithm" scheme="http://chenghehe321.github.io/tags/Algorithm/"/>
    
      <category term="Algorithm" scheme="http://chenghehe321.github.io/categories/Algorithm/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[POJ1011解题报告]]></title>
    <link href="http://chenghehe321.github.io/2014/11/27/poj1011/"/>
    <id>http://chenghehe321.github.io/2014/11/27/poj1011/</id>
    <published>2014-11-27T06:48:50.000Z</published>
    <updated>2014-11-28T14:32:51.000Z</updated>
    <content type="html"><![CDATA[<h3 id="题目链接：POJ_1011">题目链接：<a href="http://poj.org/problem?id=1011" target="_blank" rel="external">POJ 1011</a></h3>
<h3 id="题目描述：">题目描述：</h3>
<p>乔治拿来一组等长的木棒，将它们随机地砍断，使得每一节木棍的长度都不超过50个长度单位。然后他又想把这些木棍恢复到为裁截前的状态，但忘记了初始时有多少木棒以及木棒的初始长度。请你设计一个程序，帮助乔治计算木棒的可能最小长度。每一节木棍的长度都用大于零的整数表示。<br><a id="more"></a></p>
<h3 id="解题思路：">解题思路：</h3>
<p>深度优先搜索解空间，通过大量剪枝降低平均时间复杂度，最差时间复杂度为$O(2^n)$</p>
<h3 id="剪枝思路：">剪枝思路：</h3>
<p>1.将木棍按长度从大到小排序，使得搜索时能尽量在靠近根的地方发现不合适，避免大量无效的搜索。以文后提供的一组比较BT的数据为例，在所有剪枝用上，从大到小排序和从小到大排序的运行时间大概为1300ms和13000ms。</p>
<ol>
<li>分组数*每组和=总长度，其中总长度L的所有约数，分组数一定是小于等于木棍数量的，每组和一定是大于等于最长木棍长度的。</li>
<li>如果当前木棍比剩余长度还长直接跳过</li>
<li>如果剩余所有的木棍加起来还不够拼成一根木棒，则直接返回。这是大剪枝，效果明显。</li>
<li>如果当前木棍被发现不合适，则接下来和当前木棍相同长度的肯定也是不行的，跳过。这个剪枝效果也不错。</li>
<li>如果第一根木棍被发现不合适就直接返回false，因为每根木棍都是要被用上的。这也是大剪枝。</li>
<li>如果当前木棍正好拼成一个木棒，但是接下来的匹配却不成功，则可以直接返回。因为当前木棍虽然有可能会被后面的多根木棍加起来所替代，但是两种情况是等价的，也是不会匹配成功的，况且多根木棍会更灵活。所以如果当前木棍被证明是不合适的，一定会有两个或两个以上是不合适的，比如下面一组数据中</li>
</ol>
<figure class="highlight Java"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="number">15</span>,<span class="number">11</span>,<span class="number">4</span>,<span class="number">8</span>,<span class="number">8</span>,<span class="number">8</span>,<span class="number">3</span>,<span class="number">2</span>,<span class="number">1</span></div></pre></td></tr></table></figure>

<p>15，4，1虽然能拼成20，但是发现后面拼成不成功，4和1会被3和2替代，如此便能成功。</p>
<h3 id="剪枝总结：">剪枝总结：</h3>
<p>以上七种剪枝思路是能通用的，在搜索树形解空间时，当发现某个子树肯定不会有解时，和该子树相同的所有子树同样不会存在解，剪枝思路5最为典型。其次在树高度更高的地方发现子树不存在解能跳过大块无效的解空间，剪枝思路1，2，4，6，7都是这个思路的剪枝。</p>
<p>到此所有剪枝用上便能在170ms左右能AC，我在代码中将所有木棍封装为一个内部类，提供pick，unpick，firstUnpick等方法使代码更加可读，但是增加了代码的运行时常，如果拆开封装，以C风格重写算法，会在120ms左右AC。</p>
<p>在以为万事俱备的时候提交代码依然出现TLE，经过和AC代码的详细对比，发现可能是输入方式上的差别，将Scanner换成BufferedReader之后果然出现天蓝天蓝的AC，这不科学啊，Scanner还是Java1.5才新出的工具类，没理由比之前的标准输入效率还低啊。在对比BufferedReader和Scanner源码之后，发现两个类都是以InputSteamReader为基础，BufferedReader更倾向于使用缓存调高输入的效率，而Scanner尽管也有大小为1024的缓存，但更倾向于使用正则方便的处理字符。</p>
<p>在前段时间找工作笔试面试的过程中，碰到过这个问题。在第一层循环中确定分组数和每组和，确定之后就把木棍分配到每一组中，其实就成了一个负载均衡的问题，所以负载均衡问题算是这个问题的子问题。负载均衡有两种算法，精确算法就如该算法所示，深度优先搜索就是。当问题需求变为不要求准确的每组和完全相同，大致相同即可时，就能使用贪心算法了。首先依然需要将木棍按长度从大到小排序，因为贪心是从大到小去贪。然后每次把当前可用的最长木棍放入和最小的一组中，一直到木棍全部放入。当木棍数量为n，分组数量为m的时候，这是一个时间复杂度仅仅为$O(n log m)$的算法，而且仅仅是4/3倍近似，准确度较高。以下为证明过程。</p>
<p><strong>引理1</strong>：当$n \le m$时，该算法是最优的。</p>
<p><strong>引理2</strong>：当$n&gt;m$时，有$L _{max} \ge 2* l _{m+1}$。<br><strong>证明</strong>：当存在m+1个木棍时，由于按照降序排列，最后一根木棍$l_{m+1}$必然是最短的，由鸽笼原理，有一个分组里边必然有两根木棍，长度$ L_{max} \ge 2* l_{m+1}$。</p>
<p><strong>定理1</strong>：最大长度贪心算法是3/2倍近似<br><strong>证明</strong>：$ L_i=( L_i- l_j)+ l_j \le L_{max}+ \frac 1 2 * L_{max}= \frac 3 2 * L_{max}$<br>但是该分析3/2倍并不是紧致的，于是有：</p>
<p><strong>定理2[Graham, 1969]</strong>：最大长度贪心算法是4/3倍近似<br>证明就略了，略复杂，而且该分析结果是紧致的，tight case为：<br>m个分组, n(=2m+1)根木棍, 一根长度为m，其余长度都为两根，分别为m, m+1, m+2, …, 2m-1。</p>
]]></content>
    <summary type="html">
    <![CDATA[<h3 id="题目链接：POJ_1011">题目链接：<a href="http://poj.org/problem?id=1011" target="_blank" rel="external">POJ 1011</a></h3>
<h3 id="题目描述：">题目描述：</h3>
<p>乔治拿来一组等长的木棒，将它们随机地砍断，使得每一节木棍的长度都不超过50个长度单位。然后他又想把这些木棍恢复到为裁截前的状态，但忘记了初始时有多少木棒以及木棒的初始长度。请你设计一个程序，帮助乔治计算木棒的可能最小长度。每一节木棍的长度都用大于零的整数表示。<br>]]>
    
    </summary>
    
      <category term="POJ" scheme="http://chenghehe321.github.io/tags/POJ/"/>
    
      <category term="Algorithm" scheme="http://chenghehe321.github.io/tags/Algorithm/"/>
    
      <category term="DFS" scheme="http://chenghehe321.github.io/tags/DFS/"/>
    
      <category term="Java" scheme="http://chenghehe321.github.io/categories/Java/"/>
    
      <category term="POJ" scheme="http://chenghehe321.github.io/categories/Java/POJ/"/>
    
  </entry>
  
</feed>
